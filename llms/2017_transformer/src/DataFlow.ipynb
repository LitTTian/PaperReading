{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89605365",
   "metadata": {},
   "source": [
    "## Attention Is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96108144",
   "metadata": {},
   "source": [
    "- `Transformer` 结构\n",
    "\n",
    "<div\n",
    "    style=\"width: 600px; background-color: white; margin: 0 auto; padding: 20px\"\n",
    ">\n",
    "    <img src=\"https://arxiv.org/html/1706.03762v7/extracted/1706.03762v7/Figures/ModalNet-21.png\" alt=\"结构\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40cf42",
   "metadata": {},
   "source": [
    "### 第一步：分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5eb046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始句子: ['I love machine learning!!', 'Transformers are powerful models']\n",
      "分词+嵌入结果(句子被分成最小单位[tokenizer]，每个单位对应一个词嵌入向量(这里使用的是bert的嵌入层1*768))[embedding]:\n",
      "  101  -->          [CLS] --> [ 0.0136303  -0.02649042 -0.02350313 -0.00778762  0.0085892 ] ... torch.Size([1, 768])\n",
      " 1045  -->              i --> [-0.02108689  0.005904   -0.01792564 -0.00347791  0.02398458] ... torch.Size([1, 768])\n",
      " 2293  -->           love --> [ 0.06090903 -0.01906963 -0.01657766  0.02639303  0.03516982] ... torch.Size([1, 768])\n",
      " 3698  -->        machine --> [ 0.02177574  0.01318982 -0.04846223 -0.03202071 -0.02587842] ... torch.Size([1, 768])\n",
      " 4083  -->       learning --> [-0.099035   -0.03934661 -0.01086605  0.01564737 -0.00137342] ... torch.Size([1, 768])\n",
      "  999  -->              ! --> [ 0.02978682 -0.03725905 -0.0356083  -0.08191887 -0.03916362] ... torch.Size([1, 768])\n",
      "  999  -->              ! --> [ 0.02978682 -0.03725905 -0.0356083  -0.08191887 -0.03916362] ... torch.Size([1, 768])\n",
      "  102  -->          [SEP] --> [-0.01452123 -0.00996149  0.00602628 -0.00889069 -0.01851016] ... torch.Size([1, 768])\n",
      "\n",
      "  101  -->          [CLS] --> [ 0.0136303  -0.02649042 -0.02350313 -0.00778762  0.0085892 ] ... torch.Size([1, 768])\n",
      "19081  -->   transformers --> [ 0.01894439 -0.02889256 -0.07684525 -0.03968244 -0.02529856] ... torch.Size([1, 768])\n",
      " 2024  -->            are --> [-0.0134165  -0.01348164  0.0250015  -0.05152701 -0.05179376] ... torch.Size([1, 768])\n",
      " 3928  -->       powerful --> [-0.0368566  -0.02106241 -0.03385872 -0.01564265 -0.00014236] ... torch.Size([1, 768])\n",
      " 4275  -->         models --> [-0.00670358  0.02817235 -0.04282408 -0.07072101 -0.00027698] ... torch.Size([1, 768])\n",
      "  102  -->          [SEP] --> [-0.01452123 -0.00996149  0.00602628 -0.00889069 -0.01851016] ... torch.Size([1, 768])\n",
      "    0  -->          [PAD] --> [-0.01018257 -0.06154883 -0.02649689 -0.0420608   0.00116716] ... torch.Size([1, 768])\n",
      "    0  -->          [PAD] --> [-0.01018257 -0.06154883 -0.02649689 -0.0420608   0.00116716] ... torch.Size([1, 768])\n",
      "\n",
      "Attention Mask(0表示padding):\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0]])\n",
      "词表大小: 30522\n",
      "嵌入层: Embedding(30522, 768, padding_idx=0)\n",
      "句子转化后的token IDs:\n",
      " tensor([[  101,  1045,  2293,  3698,  4083,   999,   999,   102],\n",
      "        [  101, 19081,  2024,  3928,  4275,   102,     0,     0]])\n",
      "第一步的输出(输入句子的嵌入表示):\n",
      " tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
      "         [-0.0211,  0.0059, -0.0179,  ...,  0.0163,  0.0122,  0.0073],\n",
      "         [ 0.0609, -0.0191, -0.0166,  ...,  0.0064,  0.0184, -0.0200],\n",
      "         ...,\n",
      "         [ 0.0298, -0.0373, -0.0356,  ...,  0.0161,  0.0192,  0.0173],\n",
      "         [ 0.0298, -0.0373, -0.0356,  ...,  0.0161,  0.0192,  0.0173],\n",
      "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]],\n",
      "\n",
      "        [[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
      "         [ 0.0189, -0.0289, -0.0768,  ...,  0.0116, -0.0212,  0.0171],\n",
      "         [-0.0134, -0.0135,  0.0250,  ...,  0.0013, -0.0183,  0.0227],\n",
      "         ...,\n",
      "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015],\n",
      "         [-0.0102, -0.0615, -0.0265,  ..., -0.0199, -0.0372, -0.0098],\n",
      "         [-0.0102, -0.0615, -0.0265,  ..., -0.0199, -0.0372, -0.0098]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 8, 768]) <-- (batch_size, sequence_length, hidden_size)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel # huggingface的tokenizer\n",
    "from pprint import pprint\n",
    "\n",
    "# STEP1: tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "sentences = [\"I love machine learning!!\", \"Transformers are powerful models\"]\n",
    "encodings = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True) # sentence_list -> token_ids_list\n",
    "embedding_layer = model.get_input_embeddings()  # nn.Embedding(vocab_size, hidden_size)\n",
    "# 打印结果\n",
    "print(\"原始句子:\", sentences)\n",
    "print(\"分词+嵌入结果(句子被分成最小单位[tokenizer]，每个单位对应一个词嵌入向量(这里使用的是bert的嵌入层1*768))[embedding]:\")\n",
    "\n",
    "for token_ids in encodings[\"input_ids\"]:\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    for tid, tok in zip(token_ids, tokens):\n",
    "        embed = embedding_layer(tid.unsqueeze(0)) # 将token ID转化为embedding\n",
    "        print(f\"{tid.item():>5}  -->  {tok:>13} --> {embed.squeeze(0).detach().numpy()[:5]} ... {embed.shape}\")\n",
    "    print()\n",
    "\n",
    "print(\"Attention Mask(0表示padding):\\n\", encodings[\"attention_mask\"]) # NT: 0 for padding\n",
    "print(\"词表大小:\", tokenizer.vocab_size)\n",
    "print(\"嵌入层:\", embedding_layer)\n",
    "embeddings = embedding_layer(encodings[\"input_ids\"])\n",
    "print(\"句子转化后的token IDs:\\n\", encodings[\"input_ids\"])\n",
    "print(\"第一步的输出(输入句子的嵌入表示):\\n\", embeddings)\n",
    "print(embeddings.shape, \"<-- (batch_size, sequence_length, hidden_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b162710",
   "metadata": {},
   "source": [
    "### 第二步：位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9804f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "# SOL: positional encoding的实现(完整可见PositionalEncoding.py)\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "def positional_encoding(d_model, max_len=5000): # max_len: 序列的最大长度\n",
    "    pe = torch.zeros(max_len, d_model)\n",
    "    position = torch.arange(0, max_len).unsqueeze(1)\n",
    "    div_term = torch.exp(\n",
    "        torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "    )\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    pe = pe.unsqueeze(0)\n",
    "    return pe\n",
    "pe = positional_encoding(d_model=768, max_len=64)  # 这里用20维方便可视化\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36da50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "红色竖线表示在x=40这个位置，例如token(learning)不同维度需要加上的位置信息\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347.vega-embed details,\n",
       "  #altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bcbd09e12a7d4ac8b8c739bbfb797347\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-d59182899e3f2edccac4f4043d25da62\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"dimension\", \"title\": \"Dimension:N\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"name\": \"view_1\"}, {\"data\": {\"name\": \"data-b67a4a84274cd83a4c48dbdd7ce09eb6\"}, \"mark\": {\"type\": \"rule\", \"color\": \"red\", \"strokeDash\": [5, 5]}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-e85b7a82238197789d5fd831da56eef9\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"color\": \"red\", \"dx\": 5, \"dy\": -5}, \"encoding\": {\"text\": {\"field\": \"label\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}], \"height\": 400, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_1\"]}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-d59182899e3f2edccac4f4043d25da62\": [{\"embedding\": 0.0, \"position\": 0, \"dimension\": 4}, {\"embedding\": 0.15782663226127625, \"position\": 1, \"dimension\": 4}, {\"embedding\": 0.3116971552371979, \"position\": 2, \"dimension\": 4}, {\"embedding\": 0.45775455236434937, \"position\": 3, \"dimension\": 4}, {\"embedding\": 0.5923377275466919, \"position\": 4, \"dimension\": 4}, {\"embedding\": 0.7120732069015503, \"position\": 5, \"dimension\": 4}, {\"embedding\": 0.813959538936615, \"position\": 6, \"dimension\": 4}, {\"embedding\": 0.8954429626464844, \"position\": 7, \"dimension\": 4}, {\"embedding\": 0.9544808864593506, \"position\": 8, \"dimension\": 4}, {\"embedding\": 0.989593505859375, \"position\": 9, \"dimension\": 4}, {\"embedding\": 0.9999006390571594, \"position\": 10, \"dimension\": 4}, {\"embedding\": 0.9851439595222473, \"position\": 11, \"dimension\": 4}, {\"embedding\": 0.94569331407547, \"position\": 12, \"dimension\": 4}, {\"embedding\": 0.8825376033782959, \"position\": 13, \"dimension\": 4}, {\"embedding\": 0.7972599267959595, \"position\": 14, \"dimension\": 4}, {\"embedding\": 0.6919978260993958, \"position\": 15, \"dimension\": 4}, {\"embedding\": 0.5693899393081665, \"position\": 16, \"dimension\": 4}, {\"embedding\": 0.4325096309185028, \"position\": 17, \"dimension\": 4}, {\"embedding\": 0.284787654876709, \"position\": 18, \"dimension\": 4}, {\"embedding\": 0.12992730736732483, \"position\": 19, \"dimension\": 4}, {\"embedding\": -0.028190065175294876, \"position\": 20, \"dimension\": 4}, {\"embedding\": -0.18560057878494263, \"position\": 21, \"dimension\": 4}, {\"embedding\": -0.3383587896823883, \"position\": 22, \"dimension\": 4}, {\"embedding\": -0.4826357960700989, \"position\": 23, \"dimension\": 4}, {\"embedding\": -0.6148146390914917, \"position\": 24, \"dimension\": 4}, {\"embedding\": -0.7315824031829834, \"position\": 25, \"dimension\": 4}, {\"embedding\": -0.8300122618675232, \"position\": 26, \"dimension\": 4}, {\"embedding\": -0.9076365828514099, \"position\": 27, \"dimension\": 4}, {\"embedding\": -0.96250981092453, \"position\": 28, \"dimension\": 4}, {\"embedding\": -0.9932565093040466, \"position\": 29, \"dimension\": 4}, {\"embedding\": -0.9991058707237244, \"position\": 30, \"dimension\": 4}, {\"embedding\": -0.9799113273620605, \"position\": 31, \"dimension\": 4}, {\"embedding\": -0.9361540079116821, \"position\": 32, \"dimension\": 4}, {\"embedding\": -0.8689308166503906, \"position\": 33, \"dimension\": 4}, {\"embedding\": -0.7799267172813416, \"position\": 34, \"dimension\": 4}, {\"embedding\": -0.6713724136352539, \"position\": 35, \"dimension\": 4}, {\"embedding\": -0.5459895133972168, \"position\": 36, \"dimension\": 4}, {\"embedding\": -0.40692076086997986, \"position\": 37, \"dimension\": 4}, {\"embedding\": -0.2576519548892975, \"position\": 38, \"dimension\": 4}, {\"embedding\": -0.10192479938268661, \"position\": 39, \"dimension\": 4}, {\"embedding\": 0.056357722729444504, \"position\": 40, \"dimension\": 4}, {\"embedding\": 0.21322709321975708, \"position\": 41, \"dimension\": 4}, {\"embedding\": 0.3647516369819641, \"position\": 42, \"dimension\": 4}, {\"embedding\": 0.5071332454681396, \"position\": 43, \"dimension\": 4}, {\"embedding\": 0.6368028521537781, \"position\": 44, \"dimension\": 4}, {\"embedding\": 0.7505101561546326, \"position\": 45, \"dimension\": 4}, {\"embedding\": 0.8454052805900574, \"position\": 46, \"dimension\": 4}, {\"embedding\": 0.9191088676452637, \"position\": 47, \"dimension\": 4}, {\"embedding\": 0.9697737693786621, \"position\": 48, \"dimension\": 4}, {\"embedding\": 0.9961300492286682, \"position\": 49, \"dimension\": 4}, {\"embedding\": 0.9975170493125916, \"position\": 50, \"dimension\": 4}, {\"embedding\": 0.9738998413085938, \"position\": 51, \"dimension\": 4}, {\"embedding\": 0.9258706569671631, \"position\": 52, \"dimension\": 4}, {\"embedding\": 0.8546332716941833, \"position\": 53, \"dimension\": 4}, {\"embedding\": 0.7619734406471252, \"position\": 54, \"dimension\": 4}, {\"embedding\": 0.6502137184143066, \"position\": 55, \"dimension\": 4}, {\"embedding\": 0.5221555233001709, \"position\": 56, \"dimension\": 4}, {\"embedding\": 0.38100889325141907, \"position\": 57, \"dimension\": 4}, {\"embedding\": 0.23031172156333923, \"position\": 58, \"dimension\": 4}, {\"embedding\": 0.07384055852890015, \"position\": 59, \"dimension\": 4}, {\"embedding\": -0.08448058366775513, \"position\": 60, \"dimension\": 4}, {\"embedding\": -0.2406841218471527, \"position\": 61, \"dimension\": 4}, {\"embedding\": -0.3908545970916748, \"position\": 62, \"dimension\": 4}, {\"embedding\": -0.5312277674674988, \"position\": 63, \"dimension\": 4}, {\"embedding\": -0.6582850813865662, \"position\": 64, \"dimension\": 4}, {\"embedding\": -0.768841564655304, \"position\": 65, \"dimension\": 4}, {\"embedding\": -0.8601260781288147, \"position\": 66, \"dimension\": 4}, {\"embedding\": -0.9298503994941711, \"position\": 67, \"dimension\": 4}, {\"embedding\": -0.9762668013572693, \"position\": 68, \"dimension\": 4}, {\"embedding\": -0.9982118010520935, \"position\": 69, \"dimension\": 4}, {\"embedding\": -0.9951352477073669, \"position\": 70, \"dimension\": 4}, {\"embedding\": -0.967114269733429, \"position\": 71, \"dimension\": 4}, {\"embedding\": -0.9148513078689575, \"position\": 72, \"dimension\": 4}, {\"embedding\": -0.839656412601471, \"position\": 73, \"dimension\": 4}, {\"embedding\": -0.7434144616127014, \"position\": 74, \"dimension\": 4}, {\"embedding\": -0.6285378336906433, \"position\": 75, \"dimension\": 4}, {\"embedding\": -0.4979061186313629, \"position\": 76, \"dimension\": 4}, {\"embedding\": -0.3547937273979187, \"position\": 77, \"dimension\": 4}, {\"embedding\": -0.20278796553611755, \"position\": 78, \"dimension\": 4}, {\"embedding\": -0.04569905996322632, \"position\": 79, \"dimension\": 4}, {\"embedding\": 0.11253630369901657, \"position\": 80, \"dimension\": 4}, {\"embedding\": 0.2679498493671417, \"position\": 81, \"dimension\": 4}, {\"embedding\": 0.4166468679904938, \"position\": 82, \"dimension\": 4}, {\"embedding\": 0.5549001097679138, \"position\": 83, \"dimension\": 4}, {\"embedding\": 0.6792440414428711, \"position\": 84, \"dimension\": 4}, {\"embedding\": 0.7865618467330933, \"position\": 85, \"dimension\": 4}, {\"embedding\": 0.8741634488105774, \"position\": 86, \"dimension\": 4}, {\"embedding\": 0.9398530125617981, \"position\": 87, \"dimension\": 4}, {\"embedding\": 0.9819839596748352, \"position\": 88, \"dimension\": 4}, {\"embedding\": 0.9995001554489136, \"position\": 89, \"dimension\": 4}, {\"embedding\": 0.9919626712799072, \"position\": 90, \"dimension\": 4}, {\"embedding\": 0.959559977054596, \"position\": 91, \"dimension\": 4}, {\"embedding\": 0.903104841709137, \"position\": 92, \"dimension\": 4}, {\"embedding\": 0.8240122199058533, \"position\": 93, \"dimension\": 4}, {\"embedding\": 0.7242646217346191, \"position\": 94, \"dimension\": 4}, {\"embedding\": 0.6063624024391174, \"position\": 95, \"dimension\": 4}, {\"embedding\": 0.4732609689235687, \"position\": 96, \"dimension\": 4}, {\"embedding\": 0.32829657196998596, \"position\": 97, \"dimension\": 4}, {\"embedding\": 0.17510302364826202, \"position\": 98, \"dimension\": 4}, {\"embedding\": 0.01752028614282608, \"position\": 99, \"dimension\": 4}, {\"embedding\": 1.0, \"position\": 0, \"dimension\": 5}, {\"embedding\": 0.9874668121337891, \"position\": 1, \"dimension\": 5}, {\"embedding\": 0.9501814842224121, \"position\": 2, \"dimension\": 5}, {\"embedding\": 0.8890786170959473, \"position\": 3, \"dimension\": 5}, {\"embedding\": 0.8056897521018982, \"position\": 4, \"dimension\": 5}, {\"embedding\": 0.7021052241325378, \"position\": 5, \"dimension\": 5}, {\"embedding\": 0.5809215903282166, \"position\": 6, \"dimension\": 5}, {\"embedding\": 0.44517630338668823, \"position\": 7, \"dimension\": 5}, {\"embedding\": 0.2982720732688904, \"position\": 8, \"dimension\": 5}, {\"embedding\": 0.14389123022556305, \"position\": 9, \"dimension\": 5}, {\"embedding\": -0.01409643329679966, \"position\": 10, \"dimension\": 5}, {\"embedding\": -0.1717306226491928, \"position\": 11, \"dimension\": 5}, {\"embedding\": -0.32506027817726135, \"position\": 12, \"dimension\": 5}, {\"embedding\": -0.47024187445640564, \"position\": 13, \"dimension\": 5}, {\"embedding\": -0.6036361455917358, \"position\": 14, \"dimension\": 5}, {\"embedding\": -0.7218996286392212, \"position\": 15, \"dimension\": 5}, {\"embedding\": -0.8220675587654114, \"position\": 16, \"dimension\": 5}, {\"embedding\": -0.9016293287277222, \"position\": 17, \"dimension\": 5}, {\"embedding\": -0.9585906267166138, \"position\": 18, \"dimension\": 5}, {\"embedding\": -0.9915235042572021, \"position\": 19, \"dimension\": 5}, {\"embedding\": -0.9996025562286377, \"position\": 20, \"dimension\": 5}, {\"embedding\": -0.9826252460479736, \"position\": 21, \"dimension\": 5}, {\"embedding\": -0.941017210483551, \"position\": 22, \"dimension\": 5}, {\"embedding\": -0.8758211731910706, \"position\": 23, \"dimension\": 5}, {\"embedding\": -0.788671612739563, \"position\": 24, \"dimension\": 5}, {\"embedding\": -0.6817529797554016, \"position\": 25, \"dimension\": 5}, {\"embedding\": -0.5577451586723328, \"position\": 26, \"dimension\": 5}, {\"embedding\": -0.4197568893432617, \"position\": 27, \"dimension\": 5}, {\"embedding\": -0.27124688029289246, \"position\": 28, \"dimension\": 5}, {\"embedding\": -0.11593768745660782, \"position\": 29, \"dimension\": 5}, {\"embedding\": 0.042278096079826355, \"position\": 30, \"dimension\": 5}, {\"embedding\": 0.19943365454673767, \"position\": 31, \"dimension\": 5}, {\"embedding\": 0.3515901565551758, \"position\": 32, \"dimension\": 5}, {\"embedding\": 0.4949335753917694, \"position\": 33, \"dimension\": 5}, {\"embedding\": 0.6258708238601685, \"position\": 34, \"dimension\": 5}, {\"embedding\": 0.7411201596260071, \"position\": 35, \"dimension\": 5}, {\"embedding\": 0.8377919793128967, \"position\": 36, \"dimension\": 5}, {\"embedding\": 0.9134634733200073, \"position\": 37, \"dimension\": 5}, {\"embedding\": 0.9662377834320068, \"position\": 38, \"dimension\": 5}, {\"embedding\": 0.994792103767395, \"position\": 39, \"dimension\": 5}, {\"embedding\": 0.9984106421470642, \"position\": 40, \"dimension\": 5}, {\"embedding\": 0.9770026803016663, \"position\": 41, \"dimension\": 5}, {\"embedding\": 0.931104838848114, \"position\": 42, \"dimension\": 5}, {\"embedding\": 0.8618676662445068, \"position\": 43, \"dimension\": 5}, {\"embedding\": 0.7710266709327698, \"position\": 44, \"dimension\": 5}, {\"embedding\": 0.6608588695526123, \"position\": 45, \"dimension\": 5}, {\"embedding\": 0.5341253876686096, \"position\": 46, \"dimension\": 5}, {\"embedding\": 0.3940037488937378, \"position\": 47, \"dimension\": 5}, {\"embedding\": 0.24400585889816284, \"position\": 48, \"dimension\": 5}, {\"embedding\": 0.08789165318012238, \"position\": 49, \"dimension\": 5}, {\"embedding\": -0.07042567431926727, \"position\": 50, \"dimension\": 5}, {\"embedding\": -0.2269781529903412, \"position\": 51, \"dimension\": 5}, {\"embedding\": -0.37784066796302795, \"position\": 52, \"dimension\": 5}, {\"embedding\": -0.5192320942878723, \"position\": 53, \"dimension\": 5}, {\"embedding\": -0.6476082801818848, \"position\": 54, \"dimension\": 5}, {\"embedding\": -0.7597513794898987, \"position\": 55, \"dimension\": 5}, {\"embedding\": -0.8528502583503723, \"position\": 56, \"dimension\": 5}, {\"embedding\": -0.9245713949203491, \"position\": 57, \"dimension\": 5}, {\"embedding\": -0.973116934299469, \"position\": 58, \"dimension\": 5}, {\"embedding\": -0.9972700476646423, \"position\": 59, \"dimension\": 5}, {\"embedding\": -0.9964250922203064, \"position\": 60, \"dimension\": 5}, {\"embedding\": -0.9706035256385803, \"position\": 61, \"dimension\": 5}, {\"embedding\": -0.9204524159431458, \"position\": 62, \"dimension\": 5}, {\"embedding\": -0.8472290635108948, \"position\": 63, \"dimension\": 5}, {\"embedding\": -0.7527687549591064, \"position\": 64, \"dimension\": 5}, {\"embedding\": -0.6394393444061279, \"position\": 65, \"dimension\": 5}, {\"embedding\": -0.5100815296173096, \"position\": 66, \"dimension\": 5}, {\"embedding\": -0.3679378628730774, \"position\": 67, \"dimension\": 5}, {\"embedding\": -0.2165713608264923, \"position\": 68, \"dimension\": 5}, {\"embedding\": -0.05977622792124748, \"position\": 69, \"dimension\": 5}, {\"embedding\": 0.09851823002099991, \"position\": 70, \"dimension\": 5}, {\"embedding\": 0.254342257976532, \"position\": 71, \"dimension\": 5}, {\"embedding\": 0.4037908613681793, \"position\": 72, \"dimension\": 5}, {\"embedding\": 0.543117880821228, \"position\": 73, \"dimension\": 5}, {\"embedding\": 0.6688309907913208, \"position\": 74, \"dimension\": 5}, {\"embedding\": 0.7777789831161499, \"position\": 75, \"dimension\": 5}, {\"embedding\": 0.8672309517860413, \"position\": 76, \"dimension\": 5}, {\"embedding\": 0.9349446296691895, \"position\": 77, \"dimension\": 5}, {\"embedding\": 0.9792226552963257, \"position\": 78, \"dimension\": 5}, {\"embedding\": 0.998955249786377, \"position\": 79, \"dimension\": 5}, {\"embedding\": 0.9936476349830627, \"position\": 80, \"dimension\": 5}, {\"embedding\": 0.9634328484535217, \"position\": 81, \"dimension\": 5}, {\"embedding\": 0.9090684056282043, \"position\": 82, \"dimension\": 5}, {\"embedding\": 0.8319169878959656, \"position\": 83, \"dimension\": 5}, {\"embedding\": 0.733912467956543, \"position\": 84, \"dimension\": 5}, {\"embedding\": 0.617511510848999, \"position\": 85, \"dimension\": 5}, {\"embedding\": 0.4856317937374115, \"position\": 86, \"dimension\": 5}, {\"embedding\": 0.3415791094303131, \"position\": 87, \"dimension\": 5}, {\"embedding\": 0.18896427750587463, \"position\": 88, \"dimension\": 5}, {\"embedding\": 0.0316128134727478, \"position\": 89, \"dimension\": 5}, {\"embedding\": -0.12653106451034546, \"position\": 90, \"dimension\": 5}, {\"embedding\": -0.28150418400764465, \"position\": 91, \"dimension\": 5}, {\"embedding\": -0.4294200837612152, \"position\": 92, \"dimension\": 5}, {\"embedding\": -0.5665720105171204, \"position\": 93, \"dimension\": 5}, {\"embedding\": -0.6895220875740051, \"position\": 94, \"dimension\": 5}, {\"embedding\": -0.7951884269714355, \"position\": 95, \"dimension\": 5}, {\"embedding\": -0.880922257900238, \"position\": 96, \"dimension\": 5}, {\"embedding\": -0.9445747137069702, \"position\": 97, \"dimension\": 5}, {\"embedding\": -0.9845501184463501, \"position\": 98, \"dimension\": 5}, {\"embedding\": -0.9998465180397034, \"position\": 99, \"dimension\": 5}, {\"embedding\": 0.0, \"position\": 0, \"dimension\": 6}, {\"embedding\": 0.06305388361215591, \"position\": 1, \"dimension\": 6}, {\"embedding\": 0.12585683166980743, \"position\": 2, \"dimension\": 6}, {\"embedding\": 0.18815888464450836, \"position\": 3, \"dimension\": 6}, {\"embedding\": 0.24971213936805725, \"position\": 4, \"dimension\": 6}, {\"embedding\": 0.31027159094810486, \"position\": 5, \"dimension\": 6}, {\"embedding\": 0.3695962131023407, \"position\": 6, \"dimension\": 6}, {\"embedding\": 0.4274499714374542, \"position\": 7, \"dimension\": 6}, {\"embedding\": 0.4836025834083557, \"position\": 8, \"dimension\": 6}, {\"embedding\": 0.5378305912017822, \"position\": 9, \"dimension\": 6}, {\"embedding\": 0.5899181365966797, \"position\": 10, \"dimension\": 6}, {\"embedding\": 0.6396579146385193, \"position\": 11, \"dimension\": 6}, {\"embedding\": 0.6868520379066467, \"position\": 12, \"dimension\": 6}, {\"embedding\": 0.7313126921653748, \"position\": 13, \"dimension\": 6}, {\"embedding\": 0.7728629112243652, \"position\": 14, \"dimension\": 6}, {\"embedding\": 0.8113372921943665, \"position\": 15, \"dimension\": 6}, {\"embedding\": 0.8465827703475952, \"position\": 16, \"dimension\": 6}, {\"embedding\": 0.8784590363502502, \"position\": 17, \"dimension\": 6}, {\"embedding\": 0.9068393111228943, \"position\": 18, \"dimension\": 6}, {\"embedding\": 0.9316105246543884, \"position\": 19, \"dimension\": 6}, {\"embedding\": 0.9526742100715637, \"position\": 20, \"dimension\": 6}, {\"embedding\": 0.9699464440345764, \"position\": 21, \"dimension\": 6}, {\"embedding\": 0.9833585619926453, \"position\": 22, \"dimension\": 6}, {\"embedding\": 0.9928570985794067, \"position\": 23, \"dimension\": 6}, {\"embedding\": 0.9984043836593628, \"position\": 24, \"dimension\": 6}, {\"embedding\": 0.999978244304657, \"position\": 25, \"dimension\": 6}, {\"embedding\": 0.9975724220275879, \"position\": 26, \"dimension\": 6}, {\"embedding\": 0.9911965131759644, \"position\": 27, \"dimension\": 6}, {\"embedding\": 0.9808759093284607, \"position\": 28, \"dimension\": 6}, {\"embedding\": 0.9666516780853271, \"position\": 29, \"dimension\": 6}, {\"embedding\": 0.9485803842544556, \"position\": 30, \"dimension\": 6}, {\"embedding\": 0.9267339706420898, \"position\": 31, \"dimension\": 6}, {\"embedding\": 0.9011994004249573, \"position\": 32, \"dimension\": 6}, {\"embedding\": 0.8720782399177551, \"position\": 33, \"dimension\": 6}, {\"embedding\": 0.8394865393638611, \"position\": 34, \"dimension\": 6}, {\"embedding\": 0.8035537600517273, \"position\": 35, \"dimension\": 6}, {\"embedding\": 0.7644230127334595, \"position\": 36, \"dimension\": 6}, {\"embedding\": 0.7222501039505005, \"position\": 37, \"dimension\": 6}, {\"embedding\": 0.6772029399871826, \"position\": 38, \"dimension\": 6}, {\"embedding\": 0.6294605731964111, \"position\": 39, \"dimension\": 6}, {\"embedding\": 0.57921302318573, \"position\": 40, \"dimension\": 6}, {\"embedding\": 0.5266605615615845, \"position\": 41, \"dimension\": 6}, {\"embedding\": 0.4720119535923004, \"position\": 42, \"dimension\": 6}, {\"embedding\": 0.41548484563827515, \"position\": 43, \"dimension\": 6}, {\"embedding\": 0.3573042154312134, \"position\": 44, \"dimension\": 6}, {\"embedding\": 0.29770180583000183, \"position\": 45, \"dimension\": 6}, {\"embedding\": 0.23691439628601074, \"position\": 46, \"dimension\": 6}, {\"embedding\": 0.17518411576747894, \"position\": 47, \"dimension\": 6}, {\"embedding\": 0.1127568930387497, \"position\": 48, \"dimension\": 6}, {\"embedding\": 0.04988069087266922, \"position\": 49, \"dimension\": 6}, {\"embedding\": -0.013194027356803417, \"position\": 50, \"dimension\": 6}, {\"embedding\": -0.07621623575687408, \"position\": 51, \"dimension\": 6}, {\"embedding\": -0.1389348804950714, \"position\": 52, \"dimension\": 6}, {\"embedding\": -0.20110084116458893, \"position\": 53, \"dimension\": 6}, {\"embedding\": -0.2624664604663849, \"position\": 54, \"dimension\": 6}, {\"embedding\": -0.3227875530719757, \"position\": 55, \"dimension\": 6}, {\"embedding\": -0.3818237781524658, \"position\": 56, \"dimension\": 6}, {\"embedding\": -0.4393406808376312, \"position\": 57, \"dimension\": 6}, {\"embedding\": -0.49510911107063293, \"position\": 58, \"dimension\": 6}, {\"embedding\": -0.5489069223403931, \"position\": 59, \"dimension\": 6}, {\"embedding\": -0.6005204319953918, \"position\": 60, \"dimension\": 6}, {\"embedding\": -0.6497439742088318, \"position\": 61, \"dimension\": 6}, {\"embedding\": -0.6963817477226257, \"position\": 62, \"dimension\": 6}, {\"embedding\": -0.7402478456497192, \"position\": 63, \"dimension\": 6}, {\"embedding\": -0.7811681628227234, \"position\": 64, \"dimension\": 6}, {\"embedding\": -0.8189795017242432, \"position\": 65, \"dimension\": 6}, {\"embedding\": -0.8535317778587341, \"position\": 66, \"dimension\": 6}, {\"embedding\": -0.8846868872642517, \"position\": 67, \"dimension\": 6}, {\"embedding\": -0.9123212099075317, \"position\": 68, \"dimension\": 6}, {\"embedding\": -0.936324954032898, \"position\": 69, \"dimension\": 6}, {\"embedding\": -0.956602156162262, \"position\": 70, \"dimension\": 6}, {\"embedding\": -0.9730724096298218, \"position\": 71, \"dimension\": 6}, {\"embedding\": -0.9856699705123901, \"position\": 72, \"dimension\": 6}, {\"embedding\": -0.9943448305130005, \"position\": 73, \"dimension\": 6}, {\"embedding\": -0.9990625381469727, \"position\": 74, \"dimension\": 6}, {\"embedding\": -0.9998041391372681, \"position\": 75, \"dimension\": 6}, {\"embedding\": -0.9965668320655823, \"position\": 76, \"dimension\": 6}, {\"embedding\": -0.9893633723258972, \"position\": 77, \"dimension\": 6}, {\"embedding\": -0.9782225489616394, \"position\": 78, \"dimension\": 6}, {\"embedding\": -0.963188648223877, \"position\": 79, \"dimension\": 6}, {\"embedding\": -0.9443213939666748, \"position\": 80, \"dimension\": 6}, {\"embedding\": -0.9216960668563843, \"position\": 81, \"dimension\": 6}, {\"embedding\": -0.8954026699066162, \"position\": 82, \"dimension\": 6}, {\"embedding\": -0.8655455708503723, \"position\": 83, \"dimension\": 6}, {\"embedding\": -0.8322440981864929, \"position\": 84, \"dimension\": 6}, {\"embedding\": -0.795630156993866, \"position\": 85, \"dimension\": 6}, {\"embedding\": -0.7558501362800598, \"position\": 86, \"dimension\": 6}, {\"embedding\": -0.7130619883537292, \"position\": 87, \"dimension\": 6}, {\"embedding\": -0.6674357056617737, \"position\": 88, \"dimension\": 6}, {\"embedding\": -0.6191535592079163, \"position\": 89, \"dimension\": 6}, {\"embedding\": -0.5684073567390442, \"position\": 90, \"dimension\": 6}, {\"embedding\": -0.5153986215591431, \"position\": 91, \"dimension\": 6}, {\"embedding\": -0.46033912897109985, \"position\": 92, \"dimension\": 6}, {\"embedding\": -0.40344759821891785, \"position\": 93, \"dimension\": 6}, {\"embedding\": -0.3449500501155853, \"position\": 94, \"dimension\": 6}, {\"embedding\": -0.28508007526397705, \"position\": 95, \"dimension\": 6}, {\"embedding\": -0.22407560050487518, \"position\": 96, \"dimension\": 6}, {\"embedding\": -0.1621788740158081, \"position\": 97, \"dimension\": 6}, {\"embedding\": -0.09963719546794891, \"position\": 98, \"dimension\": 6}, {\"embedding\": -0.03669850528240204, \"position\": 99, \"dimension\": 6}, {\"embedding\": 1.0, \"position\": 0, \"dimension\": 7}, {\"embedding\": 0.9980101585388184, \"position\": 1, \"dimension\": 7}, {\"embedding\": 0.992048442363739, \"position\": 2, \"dimension\": 7}, {\"embedding\": 0.9821386337280273, \"position\": 3, \"dimension\": 7}, {\"embedding\": 0.9683201313018799, \"position\": 4, \"dimension\": 7}, {\"embedding\": 0.9506479501724243, \"position\": 5, \"dimension\": 7}, {\"embedding\": 0.9291924834251404, \"position\": 6, \"dimension\": 7}, {\"embedding\": 0.9040390253067017, \"position\": 7, \"dimension\": 7}, {\"embedding\": 0.8752877116203308, \"position\": 8, \"dimension\": 7}, {\"embedding\": 0.8430529832839966, \"position\": 9, \"dimension\": 7}, {\"embedding\": 0.8074630498886108, \"position\": 10, \"dimension\": 7}, {\"embedding\": 0.7686597108840942, \"position\": 11, \"dimension\": 7}, {\"embedding\": 0.7267972826957703, \"position\": 12, \"dimension\": 7}, {\"embedding\": 0.6820423603057861, \"position\": 13, \"dimension\": 7}, {\"embedding\": 0.6345730423927307, \"position\": 14, \"dimension\": 7}, {\"embedding\": 0.5845783352851868, \"position\": 15, \"dimension\": 7}, {\"embedding\": 0.532257080078125, \"position\": 16, \"dimension\": 7}, {\"embedding\": 0.47781768441200256, \"position\": 17, \"dimension\": 7}, {\"embedding\": 0.4214765727519989, \"position\": 18, \"dimension\": 7}, {\"embedding\": 0.36345821619033813, \"position\": 19, \"dimension\": 7}, {\"embedding\": 0.30399325489997864, \"position\": 20, \"dimension\": 7}, {\"embedding\": 0.243318572640419, \"position\": 21, \"dimension\": 7}, {\"embedding\": 0.18167544901371002, \"position\": 22, \"dimension\": 7}, {\"embedding\": 0.11930941045284271, \"position\": 23, \"dimension\": 7}, {\"embedding\": 0.056468550115823746, \"position\": 24, \"dimension\": 7}, {\"embedding\": -0.006597157102078199, \"position\": 25, \"dimension\": 7}, {\"embedding\": -0.06963648647069931, \"position\": 26, \"dimension\": 7}, {\"embedding\": -0.1323987990617752, \"position\": 27, \"dimension\": 7}, {\"embedding\": -0.1946340948343277, \"position\": 28, \"dimension\": 7}, {\"embedding\": -0.25609490275382996, \"position\": 29, \"dimension\": 7}, {\"embedding\": -0.31653639674186707, \"position\": 30, \"dimension\": 7}, {\"embedding\": -0.37571826577186584, \"position\": 31, \"dimension\": 7}, {\"embedding\": -0.43340474367141724, \"position\": 32, \"dimension\": 7}, {\"embedding\": -0.4893665015697479, \"position\": 33, \"dimension\": 7}, {\"embedding\": -0.5433804988861084, \"position\": 34, \"dimension\": 7}, {\"embedding\": -0.5952321887016296, \"position\": 35, \"dimension\": 7}, {\"embedding\": -0.6447150111198425, \"position\": 36, \"dimension\": 7}, {\"embedding\": -0.6916319727897644, \"position\": 37, \"dimension\": 7}, {\"embedding\": -0.7357962727546692, \"position\": 38, \"dimension\": 7}, {\"embedding\": -0.7770324349403381, \"position\": 39, \"dimension\": 7}, {\"embedding\": -0.8151761889457703, \"position\": 40, \"dimension\": 7}, {\"embedding\": -0.8500756621360779, \"position\": 41, \"dimension\": 7}, {\"embedding\": -0.8815921545028687, \"position\": 42, \"dimension\": 7}, {\"embedding\": -0.9096000790596008, \"position\": 43, \"dimension\": 7}, {\"embedding\": -0.933988094329834, \"position\": 44, \"dimension\": 7}, {\"embedding\": -0.9546589255332947, \"position\": 45, \"dimension\": 7}, {\"embedding\": -0.971530556678772, \"position\": 46, \"dimension\": 7}, {\"embedding\": -0.9845356941223145, \"position\": 47, \"dimension\": 7}, {\"embedding\": -0.9936226010322571, \"position\": 48, \"dimension\": 7}, {\"embedding\": -0.998755156993866, \"position\": 49, \"dimension\": 7}, {\"embedding\": -0.9999129772186279, \"position\": 50, \"dimension\": 7}, {\"embedding\": -0.9970912933349609, \"position\": 51, \"dimension\": 7}, {\"embedding\": -0.9903014898300171, \"position\": 52, \"dimension\": 7}, {\"embedding\": -0.9795705676078796, \"position\": 53, \"dimension\": 7}, {\"embedding\": -0.964941143989563, \"position\": 54, \"dimension\": 7}, {\"embedding\": -0.9464714527130127, \"position\": 55, \"dimension\": 7}, {\"embedding\": -0.9242351651191711, \"position\": 56, \"dimension\": 7}, {\"embedding\": -0.8983205556869507, \"position\": 57, \"dimension\": 7}, {\"embedding\": -0.8688308000564575, \"position\": 58, \"dimension\": 7}, {\"embedding\": -0.8358834981918335, \"position\": 59, \"dimension\": 7}, {\"embedding\": -0.7996094226837158, \"position\": 60, \"dimension\": 7}, {\"embedding\": -0.7601531147956848, \"position\": 61, \"dimension\": 7}, {\"embedding\": -0.7176715731620789, \"position\": 62, \"dimension\": 7}, {\"embedding\": -0.6723340749740601, \"position\": 63, \"dimension\": 7}, {\"embedding\": -0.6243206262588501, \"position\": 64, \"dimension\": 7}, {\"embedding\": -0.5738227963447571, \"position\": 65, \"dimension\": 7}, {\"embedding\": -0.5210408568382263, \"position\": 66, \"dimension\": 7}, {\"embedding\": -0.46618568897247314, \"position\": 67, \"dimension\": 7}, {\"embedding\": -0.4094752371311188, \"position\": 68, \"dimension\": 7}, {\"embedding\": -0.3511347472667694, \"position\": 69, \"dimension\": 7}, {\"embedding\": -0.2913972735404968, \"position\": 70, \"dimension\": 7}, {\"embedding\": -0.23049965500831604, \"position\": 71, \"dimension\": 7}, {\"embedding\": -0.1686851680278778, \"position\": 72, \"dimension\": 7}, {\"embedding\": -0.10619935393333435, \"position\": 73, \"dimension\": 7}, {\"embedding\": -0.04329042136669159, \"position\": 74, \"dimension\": 7}, {\"embedding\": 0.019790323451161385, \"position\": 75, \"dimension\": 7}, {\"embedding\": 0.08279230445623398, \"position\": 76, \"dimension\": 7}, {\"embedding\": 0.14546526968479156, \"position\": 77, \"dimension\": 7}, {\"embedding\": 0.20755885541439056, \"position\": 78, \"dimension\": 7}, {\"embedding\": 0.2688263952732086, \"position\": 79, \"dimension\": 7}, {\"embedding\": 0.3290245532989502, \"position\": 80, \"dimension\": 7}, {\"embedding\": 0.3879128098487854, \"position\": 81, \"dimension\": 7}, {\"embedding\": 0.4452572762966156, \"position\": 82, \"dimension\": 7}, {\"embedding\": 0.5008301138877869, \"position\": 83, \"dimension\": 7}, {\"embedding\": 0.5544094443321228, \"position\": 84, \"dimension\": 7}, {\"embedding\": 0.605782687664032, \"position\": 85, \"dimension\": 7}, {\"embedding\": 0.6547446846961975, \"position\": 86, \"dimension\": 7}, {\"embedding\": 0.7011010050773621, \"position\": 87, \"dimension\": 7}, {\"embedding\": 0.7446674108505249, \"position\": 88, \"dimension\": 7}, {\"embedding\": 0.7852699160575867, \"position\": 89, \"dimension\": 7}, {\"embedding\": 0.8227472901344299, \"position\": 90, \"dimension\": 7}, {\"embedding\": 0.856950581073761, \"position\": 91, \"dimension\": 7}, {\"embedding\": 0.8877431750297546, \"position\": 92, \"dimension\": 7}, {\"embedding\": 0.9150027632713318, \"position\": 93, \"dimension\": 7}, {\"embedding\": 0.9386210441589355, \"position\": 94, \"dimension\": 7}, {\"embedding\": 0.9585037231445312, \"position\": 95, \"dimension\": 7}, {\"embedding\": 0.9745717644691467, \"position\": 96, \"dimension\": 7}, {\"embedding\": 0.9867613911628723, \"position\": 97, \"dimension\": 7}, {\"embedding\": 0.9950238466262817, \"position\": 98, \"dimension\": 7}, {\"embedding\": 0.9993263483047485, \"position\": 99, \"dimension\": 7}], \"data-b67a4a84274cd83a4c48dbdd7ce09eb6\": [{\"x\": 40}], \"data-e85b7a82238197789d5fd831da56eef9\": [{\"x\": 40, \"label\": \"x=40\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(embeddings)\n",
    "import torch\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from tools.PositionalEncoding import PositionalEncoding\n",
    "\n",
    "# HL: 实际上一步骤max_len=8, d_model=768\n",
    "pe = PositionalEncoding(d_model=20, dropout=0)  # 这里用20维方便可视化\n",
    "x = torch.zeros(1, 100, 20)  # NT: 模拟输入句子(长度100，每个词的嵌入表示是20维)\n",
    "y = pe.forward(x)\n",
    "\n",
    "# 选择要展示的维度\n",
    "dims_to_plot = [4, 5, 6, 7]  # 可以自己选择\n",
    "\n",
    "# 构造 DataFrame\n",
    "data = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"embedding\": y[0, :, dim],\n",
    "        \"position\": list(range(100)),\n",
    "        \"dimension\": dim\n",
    "    })\n",
    "    for dim in dims_to_plot\n",
    "])\n",
    "\n",
    "# 用 Altair 绘制折线图\n",
    "chart = (\n",
    "    alt.Chart(data)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=\"position\",\n",
    "        y=\"embedding\",\n",
    "        color=alt.Color(\"dimension:N\", title=\"Dimension:N\")\n",
    "    )\n",
    "    .properties(width=800, height=400)\n",
    "    .interactive()\n",
    ")\n",
    "vline = alt.Chart(pd.DataFrame({\"x\": [40]})).mark_rule(color=\"red\", strokeDash=[5,5]).encode(x=\"x\")\n",
    "label = alt.Chart(pd.DataFrame({\"x\": [40], \"label\": [\"x=40\"]})).mark_text( align=\"left\", dx=5, dy=-5, color=\"red\" ).encode( x=\"x\", text=\"label\" )\n",
    "\n",
    "chart_with_line = chart + vline + label\n",
    "\n",
    "print(\"红色竖线表示在x=40这个位置，例如token(learning)不同维度需要加上的位置信息\")\n",
    "display(chart_with_line)\n",
    "# 热力图\n",
    "# heatmap = (\n",
    "#     alt.Chart(data)\n",
    "#     .mark_rect()\n",
    "#     .encode(\n",
    "#         x=\"position:O\",\n",
    "#         y=\"dimension:O\",\n",
    "#         color=\"embedding:Q\"\n",
    "#     )\n",
    "#     .properties(width=800, height=400)\n",
    "# )\n",
    "\n",
    "# display(heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
