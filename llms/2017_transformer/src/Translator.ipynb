{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74475a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe20f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['Two young, White males are outside near many bushes.', 'Several men in hard hats are operating a giant pulley system.', 'A little girl climbing into a wooden playhouse.']\n",
      "['Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.', 'Ein kleines Mädchen klettert in ein Spielhaus aus Holz.']\n"
     ]
    }
   ],
   "source": [
    "# 只取前200条训练数据\n",
    "train_data = dataset[\"train\"].select(range(200))\n",
    "\n",
    "# 提取源语言和目标语言文本\n",
    "src_texts = [x[\"en\"] for x in train_data]\n",
    "tgt_texts = [x[\"de\"] for x in train_data]\n",
    "\n",
    "print(len(src_texts))  # 200\n",
    "print(src_texts[:3])\n",
    "print(tgt_texts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fccb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        counter.update(sent.lower().split())\n",
    "    vocab = {'<pad>':0, '<sos>':1, '<eos>':2, '<unk>':3}\n",
    "    idx = 4\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "    return vocab\n",
    "\n",
    "src_vocab = build_vocab(src_texts)\n",
    "tgt_vocab = build_vocab(tgt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af28e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_texts, tgt_texts, src_vocab, tgt_vocab, max_len=32):\n",
    "        self.src_texts = src_texts\n",
    "        self.tgt_texts = tgt_texts\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "\n",
    "    def encode(self, text, vocab):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "        ids = [vocab.get(tok, vocab['<unk>']) for tok in tokens]\n",
    "        if len(ids) < self.max_len:\n",
    "            ids += [vocab['<pad>']] * (self.max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:self.max_len]\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = self.encode(self.src_texts[idx], self.src_vocab)\n",
    "        tgt_ids = self.encode(self.tgt_texts[idx], self.tgt_vocab)\n",
    "        return src_ids, tgt_ids\n",
    "\n",
    "train_dataset = TranslationDataset(src_texts, tgt_texts, src_vocab, tgt_vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb417522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import make_model\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = make_model(\n",
    "    src_vocab=len(src_vocab), \n",
    "    tgt_vocab=len(tgt_vocab), \n",
    "    d_model=768, h=8, d_ff=2048, N=6\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e587a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_src_mask(src):\n",
    "    # src: [batch, seq_len]\n",
    "    return (src != src_vocab['<pad>']).unsqueeze(1).unsqueeze(2)  # [B,1,1,seq_len]\n",
    "\n",
    "def make_tgt_mask(tgt):\n",
    "    # tgt: [batch, seq_len]\n",
    "    tgt_pad_mask = (tgt != tgt_vocab['<pad>']).unsqueeze(1).unsqueeze(2)  # HL: [B,1,1,seq_len]\n",
    "    seq_len = tgt.size(1)\n",
    "    tgt_sub_mask = torch.tril(torch.ones((seq_len, seq_len), device=tgt.device)).bool() # HL: 下三角矩阵\n",
    "    return tgt_pad_mask & tgt_sub_mask  # HL: [B,1,seq_len,seq_len]\n",
    "\n",
    "# TEST: mask\n",
    "# for src, tgt in train_loader:\n",
    "#     src, tgt = src.to(device), tgt.to(device)\n",
    "#     src_mask = make_src_mask(src)\n",
    "#     tgt_mask = make_tgt_mask(tgt[:, :-1])\n",
    "#     print(src.shape)\n",
    "#     print(tgt.shape)\n",
    "#     print(src_mask.shape)\n",
    "#     print(tgt_mask.shape)\n",
    "#     out = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "#     print(out.shape)  # [batch, seq_len-1, tgt_vocab_size]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386aa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e18478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST runnable\n",
    "# for src, tgt in train_loader:\n",
    "#     model.eval()\n",
    "#     src = src.to(device)\n",
    "#     tgt = tgt.to(device)\n",
    "    \n",
    "#     tgt_input = tgt[:, :-1]\n",
    "#     tgt_output = tgt[:, 1:]\n",
    "    \n",
    "#     src_mask = make_src_mask(src)\n",
    "#     tgt_mask = make_tgt_mask(tgt_input)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(src, tgt_input, src_mask, tgt_mask)  # [B, seq_len, vocab_size]\n",
    "    \n",
    "#     loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(loss)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27ba578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished, Average Loss: 7.1451\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished, Average Loss: 7.1522\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished, Average Loss: 7.1300\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished, Average Loss: 7.1615\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished, Average Loss: 7.1338\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 finished, Average Loss: 7.1347\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 finished, Average Loss: 7.1382\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 finished, Average Loss: 7.1440\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 finished, Average Loss: 7.1396\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 finished, Average Loss: 7.1407\n",
      "Saved model checkpoint to ./checkpoints/transformer_epoch10.pt\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "num_epochs = 10\n",
    "save_dir = './checkpoints'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 在 DataLoader 外包一层 tqdm\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    \n",
    "    for src, tgt in loop:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        src_mask = make_src_mask(src)\n",
    "        tgt_mask = make_tgt_mask(tgt_input)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input, src_mask, tgt_mask)  # [B, seq_len, vocab_size]\n",
    "        \n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 更新进度条显示当前 loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} finished, Average Loss: {avg_loss:.4f}\")\n",
    "    # 保存模型\n",
    "    save_path = os.path.join(save_dir, f\"transformer_epoch{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Saved model checkpoint to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69434062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def translate(model, sentence, src_vocab, tgt_vocab, max_len=32, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    # 将输入句子转为 token id\n",
    "    src_ids = [src_vocab.get(tok.lower(), src_vocab['<unk>']) for tok in sentence.split()]\n",
    "    src_ids = [src_vocab['<sos>']] + src_ids + [src_vocab['<eos>']]\n",
    "    src_tensor = torch.tensor(src_ids).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "    \n",
    "    src_mask = make_src_mask(src_tensor)\n",
    "    \n",
    "    # decoder 初始输入\n",
    "    ys = torch.tensor([[tgt_vocab['<sos>']]], device=device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        tgt_mask = make_tgt_mask(ys)\n",
    "        out = model(src_tensor, ys, src_mask, tgt_mask)  # [1, seq_len, vocab_size]\n",
    "        next_word = out[:, -1, :].argmax(-1).unsqueeze(0)  # 贪心取最大概率\n",
    "        \n",
    "        ys = torch.cat([ys, next_word], dim=1)\n",
    "        \n",
    "        if next_word.item() == tgt_vocab['<eos>']:\n",
    "            break\n",
    "    \n",
    "    # 将 token id 转回文字\n",
    "    id_to_word = {idx: word for word, idx in tgt_vocab.items()}\n",
    "    translated = [id_to_word[i.item()] for i in ys[0,1:]]  # 去掉<sos>\n",
    "    \n",
    "    return ' '.join(translated).replace('<eos>', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d80a22c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./checkpoints/transformer_epoch10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1b194f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: A man in a black shirt is playing a guitar.\n",
      "Translation: mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit mahlzeit\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "src_sentence = \"A man in a black shirt is playing a guitar.\"\n",
    "translation = translate(model, src_sentence, src_vocab, tgt_vocab, device=device)\n",
    "print(\"Source:\", src_sentence)\n",
    "print(\"Translation:\", translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
