{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d6e733",
   "metadata": {},
   "source": [
    "### Long Short Term Memory (LSTM)\n",
    "\n",
    "![lstm structure](assets/lstm_structure.png)  \n",
    "\n",
    "- context layer is modulated by three gating mechanisms:\n",
    "  - forget, input, output gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8566ebc",
   "metadata": {},
   "source": [
    "<!-- ![detailed lstm structure](assets/lstm_detailed_structure.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590757a2",
   "metadata": {},
   "source": [
    "- forget gate, input gate, output gate\n",
    "<!-- $$\n",
    "\\begin{align*}\n",
    "\\text{Gates:} \\\\\n",
    "f_t &= \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\\\\n",
    "i_t &= \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\\\\n",
    "g_t &= \\tanh(W_g x_t + U_g h_{t-1} + b_g) \\\\\n",
    "o_t &= \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\\\\n",
    "\\text{State:} \\\\\n",
    "c_t &= c_{t-1} \\odot f_t + i_t \\odot g_t \\\\\n",
    "\\text{Output:} \\\\\n",
    "h_t &= o_t \\odot \\tanh(c_t) \\\\\n",
    "\\end{align*}\n",
    "$$ -->\n",
    "|![detailed lstm structure](assets/lstm_detailed_structure.png) | $$ \\begin{align*} \\text{Gates:} \\\\ f_t &= \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\\\ i_t &= \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\\\ g_t &= \\tanh(W_g x_t + U_g h_{t-1} + b_g) \\\\ o_t &= \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\\\ \\text{State:} \\\\ c_t &= c_{t-1} \\odot f_t + i_t \\odot g_t \\\\ \\text{Output:} \\\\ h_t &= o_t \\odot \\tanh(c_t) \\\\ \\end{align*} $$ |\n",
    "| - | - |\n",
    "\n",
    "- $\\odot$: element-wise multiplication - 逐元素相乘\n",
    "  - $\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\odot \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix} = \\begin{bmatrix} 5 & 12 \\\\ 21 & 32 \\end{bmatrix}$\n",
    "- $\\sigma$: sigmoid function: $\\sigma(x) = \\frac{1}{1 + e^{-x}} \\quad (0, 1)$\n",
    "- $\\tanh$: hyperbolic tangent function: $\\text{tanh}(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\quad (-1, 1)$\n",
    "\n",
    "- 在所有的时间步中，$W, U, b$都是共享的(weight sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class MyLSTM(nn.Module):\n",
    "#     def __init__( \n",
    "#         self,\n",
    "#         input_size: int,\n",
    "#         hidden_size: int,\n",
    "#         num_layers: int = 1,\n",
    "#         bias: bool = True,\n",
    "#         # batch_first: bool = False,\n",
    "#         dropout: float = 0.0,\n",
    "#         # bidirectional: bool = False,\n",
    "#         proj_size: int = 0,\n",
    "#     ):\n",
    "#         super(MyLSTM, self).__init__()\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.lstm(x)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f09b240",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
