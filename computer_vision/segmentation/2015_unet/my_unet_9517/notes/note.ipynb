{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['background', 'vehicle'], ['dirt'], ['mud'], ['water'], ['gravel'], ['asphalt', 'other-terrain'], ['tree-trunk'], ['tree-foliage'], ['brush'], ['fence'], ['structure'], ['rock'], ['log'], ['pole', 'other-object'], ['sky'], ['grass']]\n"
     ]
    }
   ],
   "source": [
    "mapped_classes = {'background': 0, 'asphalt': 5, 'dirt': 1, 'mud': 2, 'water': 3, 'gravel': 4, 'other-terrain': 5, 'tree-trunk': 6, 'tree-foliage': 7, 'brush': 8, 'fence': 9, 'structure': 10, 'pole': 13, 'vehicle': 0, 'rock': 11, 'log': 12, 'other-object': 13, 'sky': 14, 'grass': 15}\n",
    "new_classes = [[] for _ in range(16)] \n",
    "for key in mapped_classes:\n",
    "    value = mapped_classes[key]\n",
    "    # print(value)\n",
    "    new_classes[value].append(key)\n",
    "print(new_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we count the pixel counts of all different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_map(nb_of_classes, merge_dict): \n",
    "    '''\n",
    "    construct mapping between old class and new class\n",
    "    old classes index: 1-18 (18 classes)\n",
    "    new classes index: 0-15 (16 classes, 0 represents bg, excluded from evluation) \n",
    "    '''\n",
    "    nb_of_classes += len(merge_dict)\n",
    "    map_list = [i for i in range(nb_of_classes)]\n",
    "    shift = 0\n",
    "    for i in range(nb_of_classes):\n",
    "        if i in merge_dict:\n",
    "            shift += 1\n",
    "        map_list[i] -= shift\n",
    "    for k, v in merge_dict.items():\n",
    "        map_list[k] = map_list[v]\n",
    "    return np.array(map_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 6051/6051 [00:33<00:00, 178.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of gray value range(1, 19): {1: 1794, 2: 1600840094, 3: 6857813, 4: 48116742, 5: 103405446, 6: 860988, 7: 2639454701, 8: 10507673624, 9: 203633644, 10: 1620768, 11: 60550301, 12: 3377421, 13: 118755, 14: 14315444, 15: 65429710, 16: 15645583, 17: 1350206976, 18: 1822499988}\n",
      "[118755, 1600840094, 6857813, 48116742, 103405446, 862782, 2639454701, 10507673624, 203633644, 1620768, 60550301, 14315444, 65429710, 19023004, 1350206976, 1822499988]\n",
      "background 118755\n",
      "dirt 1600840094\n",
      "mud 6857813\n",
      "water 48116742\n",
      "gravel 103405446\n",
      "other-terrain 862782\n",
      "tree-trunk 2639454701\n",
      "tree-foliage 10507673624\n",
      "brush 203633644\n",
      "fence 1620768\n",
      "structure 60550301\n",
      "rock 14315444\n",
      "log 65429710\n",
      "other-object 19023004\n",
      "sky 1350206976\n",
      "grass 1822499988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_gray_values(image_path, gray_values):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    counts = {value: (image == value).sum() for value in gray_values}\n",
    "    return counts\n",
    "\n",
    "def process_folder(folder_path, gray_values):\n",
    "    image_paths = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path) if fname.endswith(('.png'))]\n",
    "    total_counts = {value: 0 for value in gray_values}\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(count_gray_values, image_path, gray_values): image_path for image_path in image_paths}\n",
    "        with tqdm(total=len(futures), desc=\"Processing images\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    for value, count in result.items():\n",
    "                        total_counts[value] += count\n",
    "                except Exception as exc:\n",
    "                    print(f'Error processing {futures[future]}: {exc}')\n",
    "                pbar.update(1)\n",
    "\n",
    "    return total_counts\n",
    "\n",
    "folder_path = '../../data/processed/train/indexLabel'\n",
    "n_oldclasses = 18\n",
    "gray_value = range(1, n_oldclasses + 1)\n",
    "total_gray_value_count = process_folder(folder_path, gray_value)\n",
    "# total_gray_value_count = {1: 1794, 2: 1600840094, 3: 6857813, 4: 48116742, 5: 103405446, 6: 860988, 7: 2639454701, 8: 10507673624, 9: 203633644, 10: 1620768, 11: 60550301, 12: 3377421, 13: 118755, 14: 14315444, 15: 65429710, 16: 15645583, 17: 1350206976, 18: 1822499988}\n",
    "print(f'Total count of gray value {gray_value}: {total_gray_value_count}')\n",
    "merge_classes = {\n",
    "    1: 6, # asphalt -> other-terrain\n",
    "    12: 16, # pole -> other-object\n",
    "    13: 0, # exclude from evaluation\n",
    "}\n",
    "n_newclasses = 16\n",
    "mapping = compute_map(n_newclasses, merge_classes)\n",
    "new_count = [0] * n_newclasses\n",
    "for i in range(1, n_oldclasses + 1):\n",
    "    new_count[mapping[i]] += total_gray_value_count[i]\n",
    "print(new_count)\n",
    "new_classes = ['background', 'dirt', 'mud', 'water', 'gravel', 'other-terrain', 'tree-trunk', 'tree-foliage', 'brush', 'fence', 'structure', 'rock', 'log', 'other-object', 'sky', 'grass']\n",
    "count_per_class = {new_classes[i]: new_count[i] for i in range(n_newclasses)}\n",
    "for cls, count in count_per_class.items():\n",
    "    print(cls, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([118755, 1600840094, 6857813, 48116742, 103405446, 862782, 2639454701, 10507673624, 203633644, 1620768, 60550301, 14315444, 65429710, 19023004, 1350206976, 1822499988])\n",
      "tensor([     118755,  1600840094,     6857813,    48116742,   103405446,\n",
      "             862782,  2639454701, 10507673624,   203633644,     1620768,\n",
      "           60550301,    14315444,    65429710,    19023004,  1350206976,\n",
      "         1822499988])\n"
     ]
    }
   ],
   "source": [
    "# construct a torch tensor\n",
    "import torch\n",
    "print(count_per_class.values())\n",
    "pixel_count = torch.tensor(list(count_per_class.values()))\n",
    "print(pixel_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283/283 [00:03<00:00, 85.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ['background'] IoU: 0.0000\n",
      "Class ['dirt'] IoU: 0.40439\n",
      "Class ['mud'] IoU: 0.0000\n",
      "Class ['water'] IoU: 0.0000\n",
      "Class ['gravel'] IoU: 0.0000\n",
      "Class ['other-terrain'] IoU: 0.0000\n",
      "Class ['tree-trunk'] IoU: 0.37265\n",
      "Class ['tree-foliage'] IoU: 0.6337\n",
      "Class ['bush'] IoU: 1.8124e-06\n",
      "Class ['fence'] IoU: 0.0000\n",
      "Class ['structure'] IoU: 0.00017964\n",
      "Class ['rock'] IoU: 0.0000\n",
      "Class ['log'] IoU: 0.0000\n",
      "Class ['other-object'] IoU: 0.00011568\n",
      "Class ['sky'] IoU: 0.69367\n",
      "Class ['grass'] IoU: 0.2816\n",
      "Mean IoU: 0.15908714216\n",
      "\n",
      "Ious for weighted loss training:\n",
      "Class ['background'] IoU: 0.0\n",
      "Class ['dirt'] IoU: 0.4158\n",
      "Class ['mud'] IoU: 0.02104\n",
      "Class ['water'] IoU: 0.10708\n",
      "Class ['gravel'] IoU: 0.0001\n",
      "Class ['other-terrain'] IoU: 0.0\n",
      "Class ['tree-trunk'] IoU: 0.46887\n",
      "Class ['tree-foliage'] IoU: 0.6978\n",
      "Class ['bush'] IoU: 0.0001\n",
      "Class ['fence'] IoU: 0.0\n",
      "Class ['structure'] IoU: 0.1037\n",
      "Class ['rock'] IoU: 0.0\n",
      "Class ['log'] IoU: 0.1308\n",
      "Class ['other-object'] IoU: 0.0271\n",
      "Class ['sky'] IoU: 0.6733\n",
      "Class ['grass'] IoU: 0.3271\n",
      "Mean IoU: 0.185799375\n"
     ]
    }
   ],
   "source": [
    "from utils.data_loading import WSDataset\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "from utils.evaluate import test\n",
    "from unet.unet_model import UNet\n",
    "\n",
    "# test_dir = Path('../../data/processed/test')\n",
    "test_dir = Path('../../data/processed/val')\n",
    "test_img_dir = test_dir / 'image'\n",
    "test_label_dir = test_dir / 'indexLabel'\n",
    "merge_classes = {\n",
    "    1: 6, # asphalt -> other-terrain\n",
    "    12: 16, # pole -> other-object\n",
    "    13: 0, # exclude from evaluation\n",
    "}\n",
    "test_set = WSDataset(test_img_dir, test_label_dir, 0.5, 16, merge_classes, True)\n",
    "new_classes = ['background', 'dirt', 'mud', 'water', 'gravel', 'other-terrain', 'tree-trunk', 'tree-foliage', 'brush', 'fence', 'structure', 'rock', 'log', 'other-object', 'sky', 'grass']\n",
    "\n",
    "wl_checkpoint_path = './checkpoints/wl_30/checkpoint_wl_epoch30.pth'\n",
    "ce_checkpoint_path = './checkpoints/ce_30/checkpoint_epoch30.pth'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "state_dict = torch.load(ce_checkpoint_path, map_location=device)\n",
    "net1 = UNet(n_channels=3, n_classes=16, bilinear=False)\n",
    "net1.load_state_dict(state_dict)\n",
    "print(device.type)\n",
    "\n",
    "test(net1, test_set, device, new_classes)\n",
    "print()\n",
    "\n",
    "net2 = UNet(n_channels=3, n_classes=16, bilinear=False)\n",
    "state_dict = torch.load(wl_checkpoint_path, map_location=device)\n",
    "print('Ious for weighted loss training:')\n",
    "test(net2, test_set, device, new_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
