{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一次`batch_size=4`, `resize=0.5`, 训练了`epoch=5`.\n",
    "- 第二次`batch_size=1`, `resize=1`, 训练了`epoch=5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境的搭建\n",
    "cuda12.1\n",
    "pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "cuda11.7\n",
    "pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "- 修改trian.py中数据集的路径\n",
    "- 由于图片分辨率很高，我设置了scale=0.25 (2016*1512 => 504*303), 为了训练效果可以改回1\n",
    "- 由于图片分辨率很大，batch_size不能太大(<=4)\n",
    "- 我设置了scale=0.25, batch size=4才刚好不爆显存。\n",
    "- 环境搭建\n",
    "\n",
    "```shell\n",
    "conda create --name cuda117 python=3.10\n",
    "pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "pip install -r requirements.txt\n",
    "python .\\train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8d505b8bba8af9e73ebb5815bea1401a\n"
     ]
    }
   ],
   "source": [
    "# 根据时间计算hash值\n",
    "import hashlib\n",
    "import time\n",
    "# hash_time = time.time()\n",
    "# hash_time = str(hash_time).encode('utf-8')\n",
    "# hash_time = hashlib.md5(hash_time).hexdigest()\n",
    "hash_time = hashlib.md5(str(time.time()).encode('utf-8')).hexdigest()\n",
    "print(hash_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-19T221247.txt\n"
     ]
    }
   ],
   "source": [
    "# 生成日期\n",
    "import time\n",
    "date = time.strftime('%Y-%m-%d', time.localtime())\n",
    "t = time.strftime('%H%M%S', time.localtime())\n",
    "file_name = '{}T{}.txt'.format(date, t)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (inc): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down1): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): Up(\n",
      "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): Up(\n",
      "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): Up(\n",
      "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): Up(\n",
      "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(64, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "import torch\n",
    "from torchvision import models\n",
    "from unet import UNet\n",
    "from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "file_path = './checkpoints/checkpoint_epoch1.pth'\n",
    "model = UNet(n_channels=3, n_classes=18, bilinear=False)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "state_dict = torch.load(file_path)\n",
    "del state_dict['mask_values']\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于类别的合并\n",
    "\n",
    "- 初始标签图种18种类型的灰度值对应\n",
    "\n",
    "```sh\n",
    "asphalt 1 #e6194b 合并到other-terrain\n",
    "dirt 2 #3cb44b\n",
    "mud 3 #ffe119\n",
    "water 4 #0082c8\n",
    "gravel 5 #911eb4\n",
    "other-terrain 6 #46f0f0 \n",
    "tree-trunk 7 #f032e6\n",
    "tree-foliage 8 #d2f53c\n",
    "bush 9 #fabebe\n",
    "fence 10 #008080\n",
    "structure 11 #aa6e28\n",
    "pole 12 #fffac8 合并到other-object\n",
    "vehicle 13 #800000 从评估中排除(->背景类0)\n",
    "rock 14 #aaffc3\n",
    "log 15 #808000\n",
    "other-object 16 #ffd7b4\n",
    "sky 17 #000080\n",
    "grass 18 #808080\n",
    "```\n",
    "- 两种类型合并和一种类型排除\n",
    "```py\n",
    "merge_classes = {\n",
    "    1: 6, # asphalt -> other-terrain\n",
    "    12: 16, # pole -> other-object\n",
    "    13: 0, # exclude from evaluation\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bg': 0, 'asphalt': 1, 'dirt': 2, 'mud': 3, 'water': 4, 'gravel': 5, 'other-terrain': 6, 'tree-trunk': 7, 'tree-foliage': 8, 'brush': 9, 'fence': 10, 'structure': 11, 'pole': 12, 'vehicle': 13, 'rock': 14, 'log': 15, 'other-object': 16, 'sky': 17, 'grass': 18}\n",
      "[0, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 0, 11, 12, 13, 14, 15]\n",
      "{'bg': 0, 'asphalt': 5, 'dirt': 1, 'mud': 2, 'water': 3, 'gravel': 4, 'other-terrain': 5, 'tree-trunk': 6, 'tree-foliage': 7, 'brush': 8, 'fence': 9, 'structure': 10, 'pole': 13, 'vehicle': 0, 'rock': 11, 'log': 12, 'other-object': 13, 'sky': 14, 'grass': 15}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # 合并和排除之后的16种类别的灰度值对应 1-18 -> 0-15\\n{'bg': 0, 'asphalt': 5, 'dirt': 1, 'mud': 2, 'water': 3, 'gravel': 4, 'other-terrain': 5, 'tree-trunk': 6, 'tree-foliage': 7, 'brush': 8, 'fence': 9, 'structure': 10, 'pole': 13, 'vehicle': 0, 'rock': 11, 'log': 12, 'other-object': 13, 'sky': 14, 'grass': 15}\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_classes = ['bg', 'asphalt', 'dirt', 'mud', 'water', 'gravel', 'other-terrain', 'tree-trunk', 'tree-foliage', 'brush', 'fence', 'structure', 'pole', 'vehicle', 'rock', 'log', 'other-object', 'sky', 'grass']\n",
    "merge_dict ={1:6, 12:16, 13:0}\n",
    "def compute_map(nb_of_classes, merge_dict):\n",
    "    nb_of_classes += len(merge_dict)\n",
    "    map_list = [i for i in range(nb_of_classes)]\n",
    "    shift = 0\n",
    "    for i in range(nb_of_classes):\n",
    "        if i in merge_dict:\n",
    "            shift += 1\n",
    "        map_list[i] -= shift\n",
    "    for k, v in merge_dict.items():\n",
    "        map_list[k] = map_list[v]\n",
    "    return map_list\n",
    "\n",
    "original_dict = {origin_classes[i]: i for i in range(len(origin_classes))}\n",
    "print(original_dict)\n",
    "\"\"\" # 18种类别的初始灰度值对应(原始数据中并没有背景类0) 1-18\n",
    "{'asphalt': 1, 'dirt': 2, 'mud': 3, 'water': 4, 'gravel': 5, 'other-terrain': 6, 'tree-trunk': 7, 'tree-foliage': 8, 'brush': 9, 'fence': 10, 'structure': 11, 'pole': 12, 'vehicle': 13, 'rock': 14, 'log': 15, 'other-object': 16, 'sky': 17, 'grass': 18}\n",
    "\"\"\"\n",
    "\n",
    "new_map = compute_map(16, merge_dict)\n",
    "print(new_map)\n",
    "new_dict = {origin_classes[i]: new_map[i] for i in range(len(origin_classes))}\n",
    "print(new_dict)\n",
    "\"\"\" # 合并和排除之后的16种类别的灰度值对应 1-18 -> 0-15\n",
    "{'bg': 0, 'asphalt': 5, 'dirt': 1, 'mud': 2, 'water': 3, 'gravel': 4, 'other-terrain': 5, 'tree-trunk': 6, 'tree-foliage': 7, 'brush': 8, 'fence': 9, 'structure': 10, 'pole': 13, 'vehicle': 0, 'rock': 11, 'log': 12, 'other-object': 13, 'sky': 14, 'grass': 15}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于评估指标 evaluate.py\n",
    "\n",
    "```python\n",
    "def evaluate(model, val_loader, device, amp):\n",
    "    model.eval()\n",
    "    n_val = len(val_loader)  # the number of batch\n",
    "    accuracys = []\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    with torch.no_grad(): # 不计算梯度\n",
    "        for batch in tqdm(val_loader, total=n_val, desc='Validation round', unit='batch', leave=False):\n",
    "            images, mask_true = batch['image'], batch['mask']\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "\n",
    "            with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                mask_pred = model(images)\n",
    "                assert mask_true.min() >= 0 and mask_true.max() < model.n_classes, 'True mask indices should be in [0, n_classes['\n",
    "                # convert to one-hot format\n",
    "                mask_true = F.one_hot(mask_true, model.n_classes).permute(0, 3, 1, 2).float()\n",
    "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()\n",
    "            accuracy, ious, precisions, recalls = calculate_metrics(mask_pred[:, 1:], mask_true[:, 1:], model.n_classes, ignore_index=[0])\n",
    "    # accuracys_mean = np.nanmean(np.array(accuracys), axis=0)\n",
    "    ious_mean = np.nanmean(np.array(ious), axis=0)\n",
    "    precisions_mean = np.nanmean(np.array(precisions), axis=0)\n",
    "    recalls_mean = np.nanmean(np.array(recalls), axis=0)\n",
    "\n",
    "    return accuracy, ious_mean, precisions_mean, recalls_mean\n",
    "```\n",
    "\n",
    "\n",
    "- `mask_pred = F.one_hot(mask_pred.argmax(dim=1), model.n_classes).permute(0, 3, 1, 2).float()`\n",
    "  - `mask_pred`: 是模型的预测输出，通常有shape:`(batch_size, height, width)`\n",
    "  - `F.one_hot(mask_pred.argmax(dim=1), model.n_classes)`: 将预测输出转换为one-hot格式，shape:`(batch_size, n_classes, height, width)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# batch_size = 1\n",
    "# num_classes = 3\n",
    "# height = 2\n",
    "# width = 3\n",
    "# 模型predict之后的shape: batch_size * num_classes * height * width\n",
    "mask_pred = torch.tensor([\n",
    "    [\n",
    "        [[0.1, 0.4, 0.1], [0.4, 0.5, 0.1],],\n",
    "        [[0.3, 0.5, 0.6], [0.6, 0.3, 0.5],],\n",
    "        [[0.6, 0.1, 0.3], [0.0, 0.1, 0.4],],\n",
    "    ],\n",
    "]) \n",
    "print(mask_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 1, 1],\n",
      "         [1, 0, 1]]])\n",
      "tensor([[[[0, 0, 1],\n",
      "          [0, 1, 0],\n",
      "          [0, 1, 0]],\n",
      "\n",
      "         [[0, 1, 0],\n",
      "          [1, 0, 0],\n",
      "          [0, 1, 0]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 使用argmax获取最大的类别索引\n",
    "# shape = (batch_size, height, width)\n",
    "indices = mask_pred.argmax(dim=1)\n",
    "# ans = F.one_hot(mask_pred.argmax(dim=1), 3).permute(0, 3, 1, 2).float()\n",
    "print(indices)\n",
    "ans = F.one_hot(indices, 3)\n",
    "# print(ans)\n",
    "# print(indices)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 3])\n",
      "tensor([[[2, 1, 1],\n",
      "         [1, 0, 1]],\n",
      "\n",
      "        [[2, 1, 1],\n",
      "         [1, 0, 1]]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mask_pred = torch.tensor([\n",
    "    [\n",
    "        [[0.1, 0.4, 0.1], [0.4, 0.5, 0.1],],\n",
    "        [[0.3, 0.5, 0.6], [0.6, 0.3, 0.5],],\n",
    "        [[0.6, 0.1, 0.3], [0.0, 0.1, 0.4],],\n",
    "    ],\n",
    "    [\n",
    "        [[0.1, 0.4, 0.1], [0.4, 0.5, 0.1],],\n",
    "        [[0.3, 0.5, 0.6], [0.6, 0.3, 0.5],],\n",
    "        [[0.6, 0.1, 0.3], [0.0, 0.1, 0.4],],\n",
    "    ],\n",
    "])\n",
    "mask_true = torch.tensor([\n",
    "    [\n",
    "        [2, 1, 0],\n",
    "        [1, 2, 0],\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 0],\n",
    "        [0, 1, 2],\n",
    "    ],\n",
    "])\n",
    "print(mask_pred.shape)\n",
    "indices = mask_pred.argmax(dim=1)\n",
    "print(indices)\n",
    "print(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)\n",
    "print(len(indices))\n",
    "print(len(indices[0]))\n",
    "print(len(indices[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.],\n",
      "          [0., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 1.],\n",
      "          [1., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 1.],\n",
      "          [1., 0., 1.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [0., 0., 0.]]]])\n",
      "torch.Size([2, 3, 2, 3])\n",
      "3\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# One-hot编码\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# shape = (batch_size, height, width, num_classes)\n",
    "# permute之后 (batch_size, num_classes, height, width)\n",
    "mask_pred = F.one_hot(indices, 3).permute(0, 3, 1, 2).float()\n",
    "print(mask_pred)\n",
    "print(mask_pred.shape)\n",
    "n_classes = mask_pred.shape[1]\n",
    "print(n_classes)\n",
    "mask_pred = mask_pred.flatten()\n",
    "print(mask_pred)\n",
    "print(len(mask_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1])\n",
      "8\n",
      "tensor(8)\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "indices = indices.flatten()\n",
    "print(indices)\n",
    "ignore_index = [0, 2]\n",
    "# 计算indices中值不在ignore_index中的数量\n",
    "counts = sum([1 if i not in ignore_index else 0 for i in indices])\n",
    "print(counts)\n",
    "\n",
    "count = torch.tensor([1 if i not in ignore_index else 0 for i in indices])\n",
    "print(sum(count))\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m mask_pred \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask_pred)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 2 is not equal to len(dims) = 4"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices.shape[0] * indices.shape[1] * indices.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True, False, False],\n",
      "         [False, False, False]],\n",
      "\n",
      "        [[ True, False, False],\n",
      "         [False, False, False]]])\n",
      "tensor([[[ True, False, False],\n",
      "         [False,  True, False]],\n",
      "\n",
      "        [[False,  True, False],\n",
      "         [False, False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "pred_positive = (indices == 2)\n",
    "print(pred_positive)\n",
    "actual_positive = (mask_true == 2)\n",
    "print(actual_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m true_positive \u001b[38;5;241m=\u001b[39m (\u001b[43mpred_positive\u001b[49m \u001b[38;5;241m&\u001b[39m actual_positive)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(true_positive)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_positive' is not defined"
     ]
    }
   ],
   "source": [
    "true_positive = (pred_positive & actual_positive).sum().item()\n",
    "print(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 3\n"
     ]
    }
   ],
   "source": [
    "union = torch.logical_or(pred_positive, actual_positive).sum().item()\n",
    "false_positive = pred_positive.sum().item() - true_positive\n",
    "false_negative = actual_positive.sum().item() - true_positive\n",
    "print(union, false_positive, false_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8560e-03, 3.0933e-01, 8.0000e-02, 4.2182e-02, 1.0000e+00, 1.1897e-03,\n",
      "        2.9000e-04, 1.3647e-02, 4.6400e-01, 4.7347e-02, 2.9000e-01, 3.8667e-02,\n",
      "        1.4730e-01, 2.3200e-03, 1.5467e-03])\n",
      "tensor([0.2781, 0.8653, 0.7101, 0.6366, 1.0000, 0.2271, 0.0651, 0.5071, 0.9119,\n",
      "        0.6499, 0.8579, 0.6267, 0.7802, 0.3037, 0.2572])\n"
     ]
    }
   ],
   "source": [
    "pixel_counts = torch.tensor([2.3e5, 2.5e9, 1.5e7, 5.8e7, 1.1e8, 4.64e6, 3.9e9, 1.6e10, 3.4e8, 1e7, 9.8e7, 1.6e7, 1.2e8, 3.15e7, 2e9, 3e9])\n",
    "pixel_counts = pixel_counts[1:]\n",
    "\n",
    "# relative_weights\n",
    "total_pixel_count = pixel_counts.sum()\n",
    "num_classes = len(pixel_counts)\n",
    "relative_weights = total_pixel_count / (num_classes * pixel_counts)\n",
    "relative_weights = relative_weights / relative_weights.max() # normalize\n",
    "print(relative_weights)\n",
    "\n",
    "# log weights\n",
    "epsilon = 1e-6\n",
    "log_weights = torch.log(total_pixel_count/ (pixel_counts + epsilon))\n",
    "log_weights = log_weights / log_weights.max() # normalize\n",
    "print(log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
