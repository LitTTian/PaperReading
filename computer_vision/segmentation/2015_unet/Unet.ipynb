{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1110e4",
   "metadata": {},
   "source": [
    "## U-Net：用于生物医学图像分割的卷积网络\n",
    "<!-- U-Net: Convolutional Networks for Biomedical Image Segmentation -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e268d5a",
   "metadata": {},
   "source": [
    "## 一、引言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a578bf",
   "metadata": {},
   "source": [
    "1. 背景：卷积网络在视觉任务中取得突破，但生物医学分割需要\"定位+少量样本\"，现有方法无法满足；\n",
    "2. 现有方法的缺陷：滑动窗口法速度慢、定位与上下文难以兼顾、数据增强有限；\n",
    "3. 核心基础：基于全卷积网络（FCN）改进，核心是\"上采样+特征融合\"；\n",
    "4. 关键创新：\n",
    "   1. U形对成结构（收缩+扩展路径）；\n",
    "   2. 重叠瓦片策略（解决大型图像分割与GPU内存限制）；\n",
    "   3. 弹性变形数据增强（少量样本下学习变形不变性）；\n",
    "   4. 加权损失函数（分离相邻同类边界）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f60f4",
   "metadata": {},
   "source": [
    "## 二、网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12015594",
   "metadata": {},
   "source": [
    "1. 整体结构：左右对成U形结构，分为收缩路径（下采样，捕捉上下文）和扩展路径（上采样，精确定位）；\n",
    "2. 收缩路径流程：3x3卷积(无填充) -> ReLU -> 3x3卷积(无填充) -> ReLU -> 2x2最大池化(步长2)；每步通道数翻倍\n",
    "3. 扩展路径流程：上采样 -> 2x2上卷积(通道数减半) -> 与收缩路径特征图拼接（需剪裁） -> 3x3卷积 -> ReLU -> 3x3卷积 -> ReLU；\n",
    "4. 关键细节：无全连接层，共23个卷积层；输入瓦片大小需要满足偶数尺寸，以适配无缝拼接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05670a9b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; padding:10px; border-radius:5px; width:80%; margin:auto; text-align:center;\">\n",
    "    <image src=\"./assets/u-net-illustration-correct-scale2.png\" />\n",
    "    <span style=\"font-size:12px; color:gray; display:block; \">图1 U-Net架构示意图(图片最小尺寸32x32)</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d84b93",
   "metadata": {},
   "source": [
    "[完整实现代码](./my_unet_9517/unet/unet_parts.py)\n",
    "\n",
    "__双卷积块__:\n",
    "```py\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\" 输入: [B, 64, H, W] -> [B, 128, H, W] -> [B, 128, H, W] \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "```\n",
    "\n",
    "__收缩路径__:\n",
    "```py\n",
    "class Down(nn.Module):  # 红色箭头 + 2个蓝色箭头\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),  # 无参数，2x2最大池化，步长2，尺寸减半\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "```\n",
    "\n",
    "__扩展路径__:\n",
    "```py\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上采样和双卷积\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:  # NT: bilinear通过周围4个像素的加权平均值计算新像素值，align_corners保持角点对齐\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:  # NT: 转置卷积(反卷积)，能更好保留细节，但参数更多且可能过拟合 <- 论文中使用这个\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2): # HL: 这里是让后面的x1(padding)适配前面特征图x2的尺寸（论文中则相反(crop)），\n",
    "        # HL: 这样做的好处是保留了更多像素点信息，且最终输出的特征图尺寸和最初输入一致\n",
    "        x1 = self.up(x1) # 上采样 x1 -> [B, 512, 104, 104]\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)  # 拼接 => [B, 1024, 136, 136]\n",
    "        return self.conv(x)  # 双卷积 => [B, 512, 136, 136]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d9de2",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white; padding:10px; border-radius:5px; width:80%; margin:auto; text-align:center;\">\n",
    "    <image src=\"./assets/overlap-tile.png\" />\n",
    "    <span style=\"font-size:12px; color:gray; display:block; \">图2 重叠瓦片策略用于无缝分割任意大型图像</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596d01d",
   "metadata": {},
   "source": [
    "## 三、训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2722e65",
   "metadata": {},
   "source": [
    "1. 训练配置: 基于Caffe的随机梯度下降，批次大小=1（大输入瓦片优先），动量=0.99\n",
    "2. 损失函数：逐像素soft-max+交叉熵，引入权重图w(x)，核心作用：a.平衡类别频率；b.强化相邻细胞分隔边界的学习；\n",
    "3. 权重初始化：从标准差为$\\sqrt{2/N}$的高斯分布采样（N为神经元输入节点数），避免过度激活或急或不足；\n",
    "4. 数据增强（核心）：a. 随机弹性变形（3x3网络+高斯位移+双三次插值）；b.收缩路径末端dropout；c. 覆盖平移、旋转、灰度变化鲁棒性需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084e8f4",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "w(x) &= w_c(x) + w_0 \\cdot \\exp\\left(-\\frac{(d_1(x) + d_2(x))^2}{2\\sigma^2}\\right) \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d42835",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0fec8d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
