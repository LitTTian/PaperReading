{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3359870c",
   "metadata": {},
   "source": [
    "## 摘要 Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420af53c",
   "metadata": {},
   "source": [
    "我们提出了 YOLO，一种新的物体检测方法。之前关于物体检测的工作将分类器重新利用用于检测。相反，我们将对象检测框架为一个回归问题，涉及空间分离的边界框及其相关的类别概率。单个神经网络通过一次评估直接从完整图像预测边界框和类别概率。由于整个检测流程是一个单一网络，可以直接基于检测性能进行端到端优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778eff7",
   "metadata": {},
   "source": [
    "## 统一检测 Unified Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1561a",
   "metadata": {},
   "source": [
    "- 我们将物体检测的组件统一(unify)进一个单独的神经网络中。\n",
    "- 利用整个图像来做出预测并且同时预测同一类图像的所有边界框。\n",
    "- 兼容实时速度和精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96445f4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; padding: 10px; border-radius: 5px; width: 80%; text-align:center; margin: auto;\">\n",
    "    <image src=\"./assets/model.png\" alt=\"YOLO System\">\n",
    "    <a id=\"fig2\"></a>\n",
    "    <span style=\"font-size: 0.9em; color: gray;\">图2：YOLO 模型</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848fe286",
   "metadata": {},
   "source": [
    "- 我们的系统将图像分成$S \\times S$的网格(如上面是7x7)。\n",
    "- 每个网格预测$B$个边界框(bounding box)及其置信度分数。\n",
    "    - $B$个边界框的坐标: $(x, y, w, h, \\text{confidence})$\n",
    "    - $C$个类别的条件概率: $Pr(\\text{Class}_i | \\text{Object})$\n",
    "- 每个bounding box包含5个预测值: $(x, y, w, h, \\text{confidence})$\n",
    "    - $(x, y)$: 边界框中心相对于网格边界的位置\n",
    "    - $(w, h)$: 边界框的宽度和高度，相对于整张图像的宽度和高度的比例\n",
    "    - confidence: $Pr(\\text{Object}) * \\operatorname{IOU}_{\\text{pred}}^{\\text{truth}}$(预测边界框与真实边界框的IOU)\n",
    "- 测试时置信度和类别概率相乘:\n",
    "  - $$Pr(\\text{Class}_i | \\text{Object}) * Pr(\\text{Object}) * \\operatorname{IOU}_{\\text{pred}}^{\\text{truth}} = Pr(\\text{Class}_i) * \\operatorname{IOU}_{\\text{pred}}^{\\text{truth}}$$\n",
    "  - 既编码了改类别出现在该框中的概率，也反映了测试框与该对象的匹配程度。\n",
    "- 最后预测编码为$S \\times S \\times (B * 5 + C)$的张量。\n",
    "- 为了在$\\text{P}_{\\text{ASCAL}} \\text{VOC}$上评估YOLO，我们使用：\n",
    "  - $S=7, B=2, C=20$，所以输出张量大小为$7 \\times 7 \\times 30 = 1470$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8097de",
   "metadata": {},
   "source": [
    "### 网络设计 Network Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b573906",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; padding: 10px; border-radius: 5px; width: 80%; text-align:center; margin: auto;\">\n",
    "    <image src=\"./assets/net-0.png\" alt=\"The Architecture\">\n",
    "    <a id=\"fig3\"></a>\n",
    "    <span style=\"font-size: 0.9em; color: gray;\">图3：YOLO 模型架构</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73db570",
   "metadata": {},
   "source": [
    "```python\n",
    "YOLOv1(\n",
    "  (backbone): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))  # (B, 3, 448, 448) → (B, 64, 224, 224), \n",
    "    (1): LeakyReLU(negative_slope=0.1)\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  # (B, 64, 224, 224) → (B, 64, 112, 112)\n",
    "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 64, 112, 112) → (B, 192, 112, 112), \n",
    "    (4): LeakyReLU(negative_slope=0.1)\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  # (B, 192, 112, 112) → (B, 192, 56, 56)\n",
    "    (6): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))  # (B, 192, 56, 56) → (B, 128, 56, 56), \n",
    "    (7): LeakyReLU(negative_slope=0.1)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 128, 56, 56) → (B, 256, 56, 56), \n",
    "    (9): LeakyReLU(negative_slope=0.1)\n",
    "    (10): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))  # (B, 256, 56, 56) → (B, 256, 56, 56), \n",
    "    (11): LeakyReLU(negative_slope=0.1)\n",
    "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 256, 56, 56) → (B, 512, 56, 56), \n",
    "    (13): LeakyReLU(negative_slope=0.1)\n",
    "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  # (B, 512, 56, 56) → (B, 512, 28, 28)\n",
    "    (15): Sequential(\n",
    "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))  # (B, 512, 28, 28) → (B, 256, 28, 28), \n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 256, 28, 28) → (B, 512, 28, 28), \n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (16): Sequential(\n",
    "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))  # (B, 512, 28, 28) → (B, 256, 28, 28), \n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 256, 28, 28) → (B, 512, 28, 28), \n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (17): Sequential(\n",
    "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))  # (B, 512, 28, 28) → (B, 256, 28, 28), \n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 256, 28, 28) → (B, 512, 28, 28), \n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (18): Sequential(\n",
    "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (19): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))  # (B, 512, 28, 28) → (B, 512, 28, 28), \n",
    "    (20): LeakyReLU(negative_slope=0.1)\n",
    "    (21): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 512, 28, 28) → (B, 1024, 28, 28), \n",
    "    (22): LeakyReLU(negative_slope=0.1)\n",
    "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  # (B, 1024, 28, 28) → (B, 1024, 14, 14)\n",
    "    (24): Sequential(\n",
    "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))  # (B, 1024, 14, 14) → (B, 512, 14, 14), \n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 512, 14, 14) → (B, 1024, 14, 14), \n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (25): Sequential(\n",
    "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))  # (B, 1024, 14, 14) → (B, 512, 14, 14), \n",
    "      (1): LeakyReLU(negative_slope=0.1)\n",
    "      (2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 512, 14, 14) → (B, 1024, 14, 14), \n",
    "      (3): LeakyReLU(negative_slope=0.1)\n",
    "    )\n",
    "    (26): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 1024, 14, 14) → (B, 1024, 14, 14), \n",
    "    (27): LeakyReLU(negative_slope=0.1)\n",
    "    (28): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))  # (B, 1024, 14, 14) → (B, 1024, 7, 7), \n",
    "    (29): LeakyReLU(negative_slope=0.1)\n",
    "    (30): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 1024, 7, 7) → (B, 1024, 7, 7), \n",
    "    (31): LeakyReLU(negative_slope=0.1)\n",
    "    (32): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  # (B, 1024, 7, 7) → (B, 1024, 7, 7), \n",
    "    (33): LeakyReLU(negative_slope=0.1)\n",
    "  )\n",
    "  (fc_layers): Sequential(\n",
    "    (0): Flatten(start_dim=1, end_dim=-1)\n",
    "    (1): Linear(in_features=50176, out_features=4096, bias=True)  # 1024 * 7 * 7 = 50176, \n",
    "    (2): LeakyReLU(negative_slope=0.1)\n",
    "    (3): Dropout(p=0.5, inplace=False)\n",
    "    (4): Linear(in_features=4096, out_features=1470, bias=True)  # 7 * 7 * 30 = 1470, \n",
    "    (5): Sigmoid()\n",
    "  )\n",
    ")\n",
    "输入形状: torch.Size([64, 3, 448, 448])\n",
    "输出形状: torch.Size([64, 7, 7, 30])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641049d5",
   "metadata": {},
   "source": [
    "### 训练 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c8962",
   "metadata": {},
   "source": [
    "__损失函数__:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\lambda_{\\text{coord}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{\\text{obj}} \\left[ (x_i - \\hat{x}_i)^2 + (y_i - \\hat{y}_i)^2 \\right] \\\\\n",
    "+&\\lambda_{\\text{coord}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{\\text{obj}} \\left[ (\\sqrt{w_i} - \\sqrt{\\hat{w}_i})^2 + (\\sqrt{h_i} - \\sqrt{\\hat{h}_i})^2 \\right]\\\\\n",
    "+&\\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{\\text{obj}} (C_i - \\hat{C}_i)^2 \\\\\n",
    "+&\\lambda_{\\text{noobj}} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\mathbb{1}_{ij}^{\\text{noobj}} (C_i - \\hat{C}_i)^2 \\\\\n",
    "+&\\sum_{i=0}^{S^2}  \\mathbb{1}_{i}^{\\text{obj}} \\sum_{c\\in \\text{classes}} (p_i(c) - \\hat{p}_i(c))^2 & \n",
    "\\end{aligned}$$\n",
    "\n",
    "- $\\sum_{i=0}^{S^2}$: $i$ 遍历所有网格单元。\n",
    "- $\\sum_{j=0}^{B}$: $j$ 遍历每个网格单元的边界框。\n",
    "- $\\mathbb{1}_{i}^{\\text{obj}}$: 表示物体是否出现在第$i$个网格内。\n",
    "- $\\mathbb{1}_{ij}^{\\text{obj}}$: 表示第$i$个网格的第$j$个边界框负责预测该物体。 ($^{\\text{noobj}}$表示没有物体)\n",
    "- $(x_i, y_i, w_i, h_i)$: 第$i$个网格单元的第$j$个边界框的真实坐标。(加 $\\hat{}$ 表示预测值)\n",
    "- $C_i$: 第$i$个网格单元的第$j$个边界框的真实置信度。 (加 $\\hat{}$ 表示预测值)\n",
    "- $p_i(c)$: 第$i$个网格单元的类别$c$的真实条件概率。 (加 $\\hat{}$ 表示预测值)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
